# LLM Provider: openai or ollama
LLM_PROVIDER=ollama

# Model name (e.g., mistral:7b, phi:latest, gpt-4o)
LLM_MODEL=mistral:7b

# Local Ollama URL (default usually http://localhost:11434/v1)
OLLAMA_BASE_URL=http://localhost:11434/v1

# OpenAI API Key (Required if provider is openai or fallback is enabled)
OPENAI_API_KEY=your_openai_api_key_here

# Generation Parameters
TEMPERATURE=0.0
MAX_RETRIES=1

# Hybrid Fallback
FALLBACK_TO_CLOUD=False
CLOUD_FALLBACK_MODEL=gpt-4o
